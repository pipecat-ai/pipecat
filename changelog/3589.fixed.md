- Fixed OpenAI LLM stream not being closed on cancellation/exception, which could leak sockets.
