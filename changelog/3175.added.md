- Added additional functionality related to "thinking", for Google and Anthropic
  LLMs.

  1. New typed parameters for Google and Anthropic LLMs that control the
     models' thinking behavior (like how much thinking to do, and whether to
     output thoughts or thought summaries):
     - `AnthropicLLMService.ThinkingConfig`
     - `GoogleLLMService.ThinkingConfig`
  2. New frames for representing thoughts output by LLMs:
     - `LLMThoughtStartFrame`
     - `LLMThoughtTextFrame`
     - `LLMThoughtEndFrame`
  3. A generic mechanism for associating extra LLM-specific data with a function
     call in context, used specifically to support Google's function-call-related
     "thought signatures", which are necessary to ensure thinking continuity
     between function calls in a chain (where the model thinks, makes a function
     call, thinks some more, etc.). See:
     - `FunctionCallInProgressFrame.llm_specific_extra`
     - `LLMAssistantAggregator` handling of the above field
     - `GeminiLLMAdapter` handling of`"tool_call_extra"` context messages
  4. A generic mechanism for recording LLM thoughts to context, used
     specifically to support Anthropic, whose thought signatures are expected to
     appear alongside the text of the thoughts within assistant context
     messages. See:
     - `LLMThoughtEndFrame.signature`
     - `LLMAssistantAggregator` handling of the above field
     - `AnthropicLLMAdapter` handling of `"thought"` context messages
  5. A generic mechanism for recording standalone thought signatures to context,
     used specifically to support Gemini 3 Pro, which may return
     non-function-call-related thought signatures at the end of
     non-function-call assistant responses. See:
     - `LLMThoughtSignatureFrame`
     - `LLMAssistantAggregator` handling of the above frame
     - `GeminiLLMAdapter` handling of `"thought_signature"` context messages
  6. An expansion of `TranscriptProcessor` to process LLM thoughts in addition
     to user and assistant utterances. See:
     - `TranscriptProcessor.thought()`
     - `ThoughtTranscriptionMessage`, which may now also be emitted with the
       `"on_transcript_update"` event
