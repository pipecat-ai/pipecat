- Added additional functionality related to "thinking", for Google and Anthropic
  LLMs.

  1. New typed parameters for Google and Anthropic LLMs that control the
     models' thinking behavior (like how much thinking to do, and whether to
     output thoughts or thought summaries):
     - `AnthropicLLMService.ThinkingConfig`
     - `GoogleLLMService.ThinkingConfig`
  2. New frames for representing thoughts output by LLMs:
     - `LLMThoughtStartFrame`
     - `LLMThoughtTextFrame`
     - `LLMThoughtEndFrame`
  3. A mechanism for appending arbitrary context messages after a function call
     message, used specifically to support Google's function-call-related
     "thought signatures", which are necessary to ensure thinking continuity
     between function calls in a chain (where the model thinks, makes a function
     call, thinks some more, etc.). See:
     - `append_extra_context_messages` field in `FunctionInProgressFrame` and
       helper types
     - `GoogleLLMService` leveraging the new mechanism to add a Google-specific
       `"fn_thought_signature"` message
     - `LLMAssistantAggregator` handling of `append_extra_context_messages`
     - `GeminiLLMAdapter` handling of `"fn_thought_signature"` messages
  4. A generic mechanism for recording LLM thoughts to context, used
     specifically to support Anthropic, whose thought signatures are expected to
     appear alongside the text of the thoughts within assistant context
     messages. See:
     - `LLMThoughtEndFrame.signature`
     - `LLMAssistantAggregator` handling of the above field
     - `AnthropicLLMAdapter` handling of `"thought"` context messages
  5. Google-specific logic for inserting non-function-call-related thought
     signatures into the context, to help maintain thinking continuity in a
     chain of LLM calls. See:
     - `GoogleLLMService` sending `LLMMessagesAppendFrame`s to add LLM-specific
       `"non_fn_thought_signature"` messages to context
     - `GeminiLLMAdapter` handling of `"non_fn_thought_signature"` messages
  6. An expansion of `TranscriptProcessor` to process LLM thoughts in addition
     to user and assistant utterances. See:
     - `TranscriptProcessor(process_thoughts=True)` (defaults to `False`)
     - `ThoughtTranscriptionMessage`, which is now also emitted with the
       `"on_transcript_update"` event
