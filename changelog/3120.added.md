- Added `wait_for_all` argument to the base `LLMService`. When enabled, this ensures all function calls complete before returning results to the LLM (i.e., before running a new inference with those results).
